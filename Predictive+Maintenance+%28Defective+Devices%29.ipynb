{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Importing the CSV file into a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "d_failures=pd.read_csv(\"C:/Users/mfrid/Downloads/device_failure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date          object\n",
       "device        object\n",
       "failure        int64\n",
       "attribute1     int64\n",
       "attribute2     int64\n",
       "attribute3     int64\n",
       "attribute4     int64\n",
       "attribute5     int64\n",
       "attribute6     int64\n",
       "attribute7     int64\n",
       "attribute8     int64\n",
       "attribute9     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_failures.dtypes # All the dtypes look correct except for date, so we will cast it to datetime64[ns] type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_failures['date'] = pd.DataFrame(d_failures['date'], dtype='datetime64[ns]', columns=['date']) #converting date to datetime type from dtype object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the columns available to us in our DataFrame we observe the following: <br>\n",
    "-We assume that Date cannot be a significant predictor since each device has only one entry, there is no way to relate different devices and there are too many unique dates in the dataset <br>\n",
    "-Attributes 1 through 9 are all numeric with no missing values and will be evaluated as predictors <br>\n",
    "-Device will represent our target variable (value we are looking to predict, it is binary containing a value of 0 (non-failure) or 1 (failure) <br><br>\n",
    "We will divide our data into 2 sets: Training (90%) and Testing (10%) due to the low % of failures<br><br>\n",
    "<b>Preprocessing/Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X=d_failures[['attribute1','attribute2','attribute3','attribute4','attribute5','attribute6','attribute7','attribute8','attribute9']]\n",
    "#X contains all predictive attributes\n",
    "y=d_failures['failure']\n",
    "#y is our binary target variable\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = min_max_scaler.fit_transform(X) #This scales each attribute to between 0 and 1 relative to their column values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.10, random_state=77)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Selection/Creation</b><br>\n",
    "\n",
    "Since the relationship between features and the target, optimal results cannot be obtained from Logistic Regression. Instead we will use a Support Vector Machine Classifier with an RBF(radial basis function) kernel which emphasizes the euclidean distance between feature vectors. Additionally, we balance the class weight since the # of failures(1's) is not proportional and we would like to maximize the accuracy of predicting failures and non-failures. The misclassification cost has been set to 1000 to ensure a heavy penalty is levied if one of the few failures is incorrectly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=77, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.SVC(C=1000.0, class_weight='balanced',\n",
    "    kernel='rbf',\n",
    "    max_iter=-1, random_state=77, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96120481927710844"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test,y_test) #Overall % accuracy on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11961,   479],\n",
       "       [    4,     6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix #Matrix showing accurate and inaccurate predictions on the test data\n",
    "confusion_matrix(y_test,svc.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key</b><br>\n",
    "TN=[0,0] <br>\n",
    "FN=[1,0] <br>\n",
    "FP=[0,1] <br>\n",
    "TP=[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107207,   4741],\n",
       "       [    33,     63]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix #Matrix showing accurate and inaccurate predictions on the training data\n",
    "confusion_matrix(y_train,svc.predict(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key</b><br>\n",
    "TN=[0,0] <br>\n",
    "FN=[1,0] <br>\n",
    "FP=[0,1] <br>\n",
    "TP=[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119168,   5220],\n",
       "       [    37,     69]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix #Matrix showing accurate and inaccurate predictions on all data\n",
    "confusion_matrix(y,svc.predict(X_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key</b><br>\n",
    "TN=[0,0] <br>\n",
    "FN=[1,0] <br>\n",
    "FP=[0,1] <br>\n",
    "TP=[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Rebuilding the Model with All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=77, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as previous model, but with all data\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(C=1000.0, class_weight='balanced',\n",
    "    kernel='rbf',\n",
    "    max_iter=-1, random_state=77, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "svc.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95866467460279214"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_scaled,y)#Overall % accuracy on all data using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[119279,   5109],\n",
       "       [    37,     69]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y,svc.predict(X_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Key</b><br>\n",
    "TN=[0,0] <br>\n",
    "FN=[1,0] <br>\n",
    "FP=[0,1] <br>\n",
    "TP=[1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Building a Truth Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_perfect_predictions = (y==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124388,      0],\n",
       "       [     0,    106]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix((y==1), y_perfect_predictions) #Represents actual number of failures and non-failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Failures= 106 <br>\n",
    "True Non-Failures=124,388"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis of Model Predictive Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failures Accurately Predicted: 65.09 Percent\n",
      "Failures Incorrectly Predicted: 34.91 Percent\n",
      "Non-Failures Accurately Predicted: 95.89 Percent\n",
      "Non-Failures Incorrectly Predicted: 4.11 Percent\n"
     ]
    }
   ],
   "source": [
    "TP=69/106*100\n",
    "FP=100-TP\n",
    "TN=119279/124388*100\n",
    "FN=100-TN\n",
    "print(\"Failures Accurately Predicted: %.2f Percent\" % TP)\n",
    "print(\"Failures Incorrectly Predicted: %.2f Percent\" % FP)\n",
    "print(\"Non-Failures Accurately Predicted: %.2f Percent\" % TN)\n",
    "print(\"Non-Failures Incorrectly Predicted: %.2f Percent\" % FN)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
